{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":12246743,"sourceType":"datasetVersion","datasetId":7715026},{"sourceId":12246751,"sourceType":"datasetVersion","datasetId":7715367}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install -q spacy==3.8.7\n!pip install -q fuzzywuzzy\n!pip install -q tqdm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T13:18:56.092789Z","iopub.execute_input":"2025-06-22T13:18:56.093327Z","iopub.status.idle":"2025-06-22T13:19:04.943431Z","shell.execute_reply.started":"2025-06-22T13:18:56.093302Z","shell.execute_reply":"2025-06-22T13:19:04.942617Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# ======================================================================\n# SCRIPT: 02_convert_to_spacy_format_fuzzy.py (Fixed Overlapping Spans)\n# PURPOSE:\n#   - Improved entity matching using multiple answer variants\n#   - Convert to spaCy DocBin format for training\n#   - Handles overlapping entity spans safely\n# ======================================================================\n\nimport json\nfrom pathlib import Path\nimport spacy\nfrom spacy.tokens import DocBin\nfrom fuzzywuzzy import fuzz\nfrom tqdm import tqdm\nimport re\n\n# --- Paths ---\nINPUT_JSON_PATH = Path('/kaggle/input/normalized-processes-data/train_data.json')\nOUTPUT_SPACY_PATH = Path('/kaggle/working/spacy_train_data.spacy')\n\n# --- Config ---\nFUZZY_MATCH_THRESHOLD = 85\n\n# --- Load data ---\nwith open(INPUT_JSON_PATH, 'r', encoding='utf-8') as f:\n    dataset = json.load(f)\n\nprint(f\"üìÇ Loaded {len(dataset)} training samples\")\n\n# --- NLP pipeline ---\nnlp = spacy.blank(\"en\")\ndoc_bin = DocBin()\nlabel_counts = {}\n\n# --- Helper: Generate multiple forms of answer ---\ndef generate_variants(answer):\n    answer = answer.strip()\n    variants = set()\n\n    variants.add(answer.lower())\n    variants.add(answer.replace(\",\", \"\"))\n    variants.add(re.sub(r\"[^\\w\\s]\", \"\", answer))\n    variants.add(\" \".join(answer.split()))\n    variants.add(answer.strip(' .').title())\n\n    words_only = re.sub(r\"[^a-zA-Z\\s]\", \"\", answer)\n    if words_only.strip():\n        variants.add(words_only.strip().lower())\n\n    return list(variants)\n\n# --- Fuzzy Matcher ---\ndef find_entity_spans(text, answer, label):\n    candidates = []\n    variants = generate_variants(answer)\n\n    for variant in variants:\n        for i in range(len(text)):\n            window = text[i:i + len(variant) + 10]\n            score = fuzz.partial_ratio(variant.lower(), window.lower())\n            if score >= FUZZY_MATCH_THRESHOLD:\n                start = text.lower().find(window.lower())\n                if start != -1:\n                    end = start + len(window)\n                    candidates.append((start, end, label))\n                    return candidates\n    return candidates\n\n# --- Build DocBin ---\nfor item in tqdm(dataset):\n    text = item['context']\n    entities = []\n\n    for label, answers in item['ground_truth'].items():\n        if isinstance(answers, str):\n            answers = [answers]\n\n        found = False\n        for answer in answers:\n            if not answer.strip():\n                continue\n            match = find_entity_spans(text, answer, label)\n            if match:\n                entities.extend(match)\n                label_counts[label] = label_counts.get(label, 0) + 1\n                found = True\n                break\n\n        if not found:\n            print(f\"‚ùå No match for '{' / '.join(answers)}' ({label}) in file {item['file_name']}\")\n\n    doc = nlp.make_doc(text)\n    spans = []\n    used_tokens = set()\n\n    for start, end, label in entities:\n        span = doc.char_span(start, end, label=label)\n        if span is not None:\n            span_tokens = set(range(span.start, span.end))\n            if not span_tokens & used_tokens:\n                spans.append(span)\n                used_tokens.update(span_tokens)\n\n    doc.ents = spans\n    doc_bin.add(doc)\n\n# --- Save Output ---\ndoc_bin.to_disk(OUTPUT_SPACY_PATH)\nprint(f\"\\n‚úÖ Saved .spacy training file to: {OUTPUT_SPACY_PATH}\")\nprint(f\"üìä Entity Label Counts: {label_counts}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T13:19:13.930093Z","iopub.execute_input":"2025-06-22T13:19:13.930385Z","iopub.status.idle":"2025-06-22T13:19:31.762701Z","shell.execute_reply.started":"2025-06-22T13:19:13.930358Z","shell.execute_reply":"2025-06-22T13:19:31.761904Z"}},"outputs":[{"name":"stdout","text":"üìÇ Loaded 9 training samples\n","output_type":"stream"},{"name":"stderr","text":" 11%|‚ñà         | 1/9 [00:00<00:06,  1.17it/s]","output_type":"stream"},{"name":"stdout","text":"‚ùå No match for '15' (Renewal Notice (Days)) in file 6683127-House-Rental-Contract-GERALDINE-GALINATO-v2-Page-1\n","output_type":"stream"},{"name":"stderr","text":" 33%|‚ñà‚ñà‚ñà‚ñé      | 3/9 [00:04<00:08,  1.37s/it]","output_type":"stream"},{"name":"stdout","text":"‚ùå No match for '90' (Renewal Notice (Days)) in file 18325926-Rental-Agreement-1\n‚ùå No match for '30' (Renewal Notice (Days)) in file 36199312-Rental-Agreement\n","output_type":"stream"},{"name":"stderr","text":" 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 4/9 [00:04<00:04,  1.13it/s]","output_type":"stream"},{"name":"stdout","text":"‚ùå No match for '3000 / 3,000.00 / Three Thousand' (Agreement Value) in file 44737744-Maddireddy-Bhargava-Reddy-Rental-Agreement\n‚ùå No match for '20 September 2010' (Agreement Start Date) in file 44737744-Maddireddy-Bhargava-Reddy-Rental-Agreement\n‚ùå No match for '19 July 2011' (Agreement End Date) in file 44737744-Maddireddy-Bhargava-Reddy-Rental-Agreement\n‚ùå No match for '' (Renewal Notice (Days)) in file 44737744-Maddireddy-Bhargava-Reddy-Rental-Agreement\n","output_type":"stream"},{"name":"stderr","text":" 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 5/9 [00:06<00:05,  1.26s/it]","output_type":"stream"},{"name":"stdout","text":"‚ùå No match for 'M.V.V. Vijaya Shankar' (Party One) in file 44737744-Maddireddy-Bhargava-Reddy-Rental-Agreement\n","output_type":"stream"},{"name":"stderr","text":" 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 6/9 [00:06<00:02,  1.08it/s]","output_type":"stream"},{"name":"stdout","text":"‚ùå No match for '31.02.2011' (Agreement End Date) in file 47854715-RENTAL-AGREEMENT\n‚ùå No match for '1 April 2010' (Agreement Start Date) in file 50070534-RENTAL-AGREEMENT\n","output_type":"stream"},{"name":"stderr","text":" 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 7/9 [00:08<00:02,  1.11s/it]","output_type":"stream"},{"name":"stdout","text":"‚ùå No match for '30 March 2011' (Agreement End Date) in file 50070534-RENTAL-AGREEMENT\n‚ùå No match for '90' (Renewal Notice (Days)) in file 50070534-RENTAL-AGREEMENT\n‚ùå No match for '31 March 2012' (Agreement End Date) in file 54770958-Rental-Agreement\n‚ùå No match for '90' (Renewal Notice (Days)) in file 54770958-Rental-Agreement\n‚ùå No match for 'K. Parthasarathy' (Party One) in file 54770958-Rental-Agreement\n","output_type":"stream"},{"name":"stderr","text":"100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:17<00:00,  1.96s/it]","output_type":"stream"},{"name":"stdout","text":"\n‚úÖ Saved .spacy training file to: /kaggle/working/spacy_train_data.spacy\nüìä Entity Label Counts: {'Agreement Value': 8, 'Agreement Start Date': 7, 'Agreement End Date': 5, 'Party One': 7, 'Party Two': 9, 'Renewal Notice (Days)': 3}\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# ======================================================================\n# SCRIPT: 02_convert_to_spacy_format_fuzzy_test.py\n# PURPOSE:\n#   - Convert normalized test_data.json to spaCy DocBin format\n#   - Uses fuzzy matching to find entity spans\n# ======================================================================\n\nimport json\nfrom pathlib import Path\nimport spacy\nfrom spacy.tokens import DocBin\nfrom fuzzywuzzy import fuzz\nfrom tqdm import tqdm\nimport re\n\n# --- Paths (Updated for test set) ---\nINPUT_JSON_PATH = Path('/kaggle/input/normalised-test-processed-data/test_data.json')\nOUTPUT_SPACY_PATH = Path('/kaggle/working/spacy_test_data.spacy')\n\n# --- Config ---\nFUZZY_MATCH_THRESHOLD = 85\n\n# --- Load data ---\nwith open(INPUT_JSON_PATH, 'r', encoding='utf-8') as f:\n    dataset = json.load(f)\n\nprint(f\"üìÇ Loaded {len(dataset)} test samples\")\n\n# --- NLP pipeline ---\nnlp = spacy.blank(\"en\")\ndoc_bin = DocBin()\nlabel_counts = {}\n\n# --- Helper: Generate multiple forms of answer ---\ndef generate_variants(answer):\n    answer = answer.strip()\n    variants = set()\n\n    # Strip and lowercase\n    variants.add(answer.lower())\n\n    # Remove commas\n    variants.add(answer.replace(\",\", \"\"))\n\n    # Remove currency symbols and punctuation\n    variants.add(re.sub(r\"[^\\w\\s]\", \"\", answer))\n\n    # Normalize whitespace\n    variants.add(\" \".join(answer.split()))\n\n    # Remove leading/trailing punctuations and normalize case\n    variants.add(answer.strip(' .').title())\n\n    # Remove non-letter chars for verbal forms\n    words_only = re.sub(r\"[^a-zA-Z\\s]\", \"\", answer)\n    if words_only.strip():\n        variants.add(words_only.strip().lower())\n\n    return list(variants)\n\n# --- Fuzzy Matcher ---\ndef find_entity_spans(text, answer, label):\n    candidates = []\n    variants = generate_variants(answer)\n\n    for variant in variants:\n        for i in range(len(text)):\n            window = text[i:i + len(variant) + 10]\n            score = fuzz.partial_ratio(variant.lower(), window.lower())\n            if score >= FUZZY_MATCH_THRESHOLD:\n                start = text.lower().find(window.lower())\n                if start != -1:\n                    end = start + len(window)\n                    candidates.append((start, end, label))\n                    return candidates  # return first match\n    return candidates\n\n# --- Build DocBin ---\nfor item in tqdm(dataset):\n    text = item['context']\n    entities = []\n\n    for label, answers in item['ground_truth'].items():\n        if isinstance(answers, str):\n            answers = [answers]\n\n        found = False\n        for answer in answers:\n            if not answer.strip():\n                continue\n            match = find_entity_spans(text, answer, label)\n            if match:\n                entities.extend(match)\n                label_counts[label] = label_counts.get(label, 0) + 1\n                found = True\n                break\n\n        if not found:\n            print(f\"‚ùå No match for '{' / '.join(answers)}' ({label}) in file {item['file_name']}\")\n\n    doc = nlp.make_doc(text)\n    spans = [doc.char_span(start, end, label=label) for start, end, label in entities if doc.char_span(start, end, label=label)]\n    doc.ents = spans\n    doc_bin.add(doc)\n\n# --- Save Output ---\ndoc_bin.to_disk(OUTPUT_SPACY_PATH)\nprint(f\"\\n‚úÖ Saved .spacy test file to: {OUTPUT_SPACY_PATH}\")\nprint(f\"üìä Entity Label Counts: {label_counts}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T13:19:36.943869Z","iopub.execute_input":"2025-06-22T13:19:36.944409Z","iopub.status.idle":"2025-06-22T13:19:41.026393Z","shell.execute_reply.started":"2025-06-22T13:19:36.944385Z","shell.execute_reply":"2025-06-22T13:19:41.025751Z"}},"outputs":[{"name":"stdout","text":"üìÇ Loaded 4 test samples\n","output_type":"stream"},{"name":"stderr","text":" 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 2/4 [00:01<00:01,  1.10it/s]","output_type":"stream"},{"name":"stdout","text":"‚ùå No match for '31 March 2011' (Agreement End Date) in file 95980236-Rental-Agreement\n‚ùå No match for '14 November 2013' (Agreement End Date) in file 156155545-Rental-Agreement-Kns-Home\n‚ùå No match for '30' (Renewal Notice (Days)) in file 156155545-Rental-Agreement-Kns-Home\n","output_type":"stream"},{"name":"stderr","text":"100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:03<00:00,  1.02it/s]","output_type":"stream"},{"name":"stdout","text":"\n‚úÖ Saved .spacy test file to: /kaggle/working/spacy_test_data.spacy\nüìä Entity Label Counts: {'Agreement Value': 4, 'Agreement Start Date': 4, 'Agreement End Date': 2, 'Renewal Notice (Days)': 3, 'Party One': 4, 'Party Two': 4}\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}