```markdown
# ðŸ§¾ Meta Data Extraction from Documents

## ðŸ“Œ Problem Statement

Build an **AI/ML system** to extract key metadata fields from documents, which can be either `.docx` files or scanned images (`.png`, `.jpg`)â€”without using any **rule-based or static logic (regex, templates, etc.)**. The system should generalize well across varying document formats and templates.

### Target Fields to Extract:
- Agreement Start Date
- Agreement End Date
- Renewal Notice (Days)
- Party One
- Party Two
- Agreement Value

---

## ðŸ—‚ï¸ Folder Structure

```
ml_document_extractor/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ train/                       # .docx and image files for training
â”‚   â”œâ”€â”€ test/                        # .docx and image files for testing
â”‚   â”œâ”€â”€ train.csv                    # Ground truth for training files
â”‚   â””â”€â”€ test.csv                     # Ground truth for test files
â”œâ”€â”€ processed_data/
â”‚   â”œâ”€â”€ train_data.json              # Preprocessed + normalized training data
â”‚   â””â”€â”€ test_data.json               # Preprocessed + normalized test data
â”œâ”€â”€ spacy_train_data.spacy           # spaCy DocBin for training
â”œâ”€â”€ spacy_test_data.spacy            # spaCy DocBin for testing
â”œâ”€â”€ 01_preprocess_data.py            # Extracts and normalizes both context and labels
â”œâ”€â”€ 02_prepare_for_finetuning.py     # Generates .spacy training and test data
â”œâ”€â”€ 03_fineTune_predict_and_evaluate.ipynb  # Fine-tunes model and evaluates on test set
â””â”€â”€ README.md                        # This file
```

---

## ðŸ§  Solution Overview

This project uses a **spaCy Named Entity Recognition (NER)** model to extract metadata fields as entities from document text. The model is trained on a small, domain-specific dataset by:

1. Extracting text from `.docx` and `.png/.jpg` documents.
2. Normalizing both the **context** and **ground truth labels** for format consistency.
3. Preparing training-ready data using fuzzy span matching.
4. Fine-tuning a spaCy NER model and evaluating performance.

> â— **Note:** No rule-based logic, such as regex patterns or template heuristics, is used. Normalization ensures consistent formatting only.

---

## âš™ï¸ Scripts and Workflow

### ðŸ”¹ 01_preprocess_data.py

- Extracts raw text from `.docx` files using `python-docx`, and from images using `pytesseract`.
- Loads `train.csv` and `test.csv` to get ground truth metadata.
- Cleans and **normalizes both the context and label values**:
  - Dates â†’ e.g., `31.03.2022` or `March 31st, 2022` â†’ `31 March 2022`
  - Numeric â†’ e.g., `3,000` or `Three Thousand` â†’ `3000`, `3,000.00`, etc.
  - Names â†’ Proper casing and whitespace
  - Duration â†’ `five months` or `5 month(s)` â†’ `5`

ðŸ“¤ Outputs:
- `processed_data/train_data.json`
- `processed_data/test_data.json`

---

### ðŸ”¹ 02_prepare_for_finetuning.py

- Reads the preprocessed JSON files from Step 1.
- Uses **fuzzy string matching (with multiple variants)** to find entity spans in the context text.
- Converts data to **spaCy's DocBin format**, required for training.

ðŸ“¤ Outputs:
- `spacy_train_data.spacy`
- `spacy_test_data.spacy`

âœ”ï¸ Also logs unmatched entities and their file names for debugging purposes.

---

### ðŸ”¹ 03_fineTune_predict_and_evaluate.ipynb

- Loads training `.spacy` data and fine-tunes a **blank English spaCy model** using the NER component.
- Uses a dropout + optimizer loop for 30 iterations to minimize training loss.
- Evaluates the model on the test data `.spacy` file using spaCy's built-in evaluation.

ðŸ“Š Evaluation Metrics:
- **Per Field Recall** as specified:
```
Recall = True Matches / (True Matches + Misses)
```
- Also reports Precision, F1, and a breakdown per entity label.

ðŸ“¤ Outputs:
- Trained model in: `/kaggle/working/fine_tuned_model`
- Printed predictions and scores from the test set

---

## âœ… Key Highlights

- âœ… No regex, rule-based, or heuristic logic.
- âœ… Clean normalization on both context and labels ensures matching is based purely on format consistency.
- âœ… Robust fuzzy span matching handles inconsistencies between label and text spans.
- âœ… Precision, Recall, F1 reported entity-wise, exactly as required.

---

## ðŸ“Š Sample Evaluation Output

```
ðŸ“¦ Loading fine-tuned model...
ðŸ“‚ Loading test data...

ðŸ” Evaluation Results:
âœ… Precision: 1.00
âœ… Recall:    1.00
âœ… F1 Score:  1.00
ðŸ“Š Number of Examples Evaluated: 4

ðŸ“‹ Entity-wise Breakdown:

* Agreement End Date: Precision=1.00, Recall=1.00, F1=1.00
```

---

## ðŸ” To Reproduce

1. Place `.docx` and `.png/.jpg` files inside `data/train/` and `data/test/`.
2. Update `train.csv` and `test.csv` with correct filenames and ground truth.
3. Run the scripts in this order:
   ```bash
   python 01_preprocess_data.py
   python 02_prepare_for_finetuning.py
   ```
4. Open and run all cells in:
   ```
   03_fineTune_predict_and_evaluate.ipynb
   ```

---

## ðŸ§ª Optional REST API

> As an optional step, you can wrap the final trained spaCy model into a Flask/FastAPI web service. This allows the metadata extraction system to be accessed as a RESTful API.

---
